---
Title: CPU数が多いとTensorflow&kerasの機械学習が遅い件
Category:
- python
- cuda
Date: 2019-06-23T23:52:38+09:00
URL: https://blog.turai.work/entry/20190623/1561301558
EditURL: https://blog.hatena.ne.jp/thr3a/thr3a.hatenablog.com/atom/entry/17680117127205554255
---

# 概要

どういうわけか、CPUが多いサーバーだと学習に時間がかかるんじゃないかという話があった。そんなことないやろと思いつつ、公平にAWSでベンチマークを撮ってみたが、やはり**CPU数が多ければ多いほど遅くなってしまう**。。

# 検証環境

- AWS p3.2xlargeインスタンス
  - GPU: NVIDIA Tesla V100 GPU x 1
  - CPU: 8コア
  - メモリ: 61GB
- tensorflow 1.13
- keras 2.2.4

nvidia-dockerを使ってCUDAの環境を構築し、その中で[keras公式レポジトリ内のexampleコード](https://github.com/keras-team/keras/tree/master/examples)を実行して掛かった時間を計測する。

ちなみに[githubのレポジトリ](https://github.com/thr3a/gpu)を使うとそれらがスクリプト化されている。

```sh
git clone https://github.com/thr3a/gpu.git
cd gpu
make build
make benchmark1 CPUS=0-1 # 使用するコアをCPUSで渡す デフォルト0のみ
```

# babi_rnn.pyを実行したときのベンチマーク結果

FacebookのbAbIデータセットを用いた学習　自然言語処理系のはず

## CPU数１個の場合 

- かかった時間 8分44秒
- １エポックあたりの平均 25秒

## CPU数２個の場合

- かかった時間 7分23秒
- １エポックあたりの平均 21〜22秒

## CPU数４個の場合

- かかった時間 ７分３７秒
- １エポックあたりの平均 22秒

## CPU数８個の場合

- かかった時間 8分06秒
- １エポックあたりの平均 24秒

結果２コアが１番速く終わることになる

# cifar10_cnn.pyを実行したときのベンチマーク結果

いわゆる画像分類

## CPU数１個の場合 

- かかった時間 5分18秒
- １エポックあたりの平均 31秒

## CPU数２個の場合

- かかった時間 4分14秒
- １エポックあたりの平均 25秒

## CPU数４個の場合

- かかった時間 4分40秒
- １エポックあたりの平均 27秒

## CPU数８個の場合

- かかった時間 5分11秒
- １エポックあたりの平均 30秒

これも２コアが一番速かった

# 結果

２つのベンチマークを表にすると以下

|       | babi_rnn.py | cifar10_cnn.py |
|-------|-------------|----------------|
| 1コア | 8:44        | 5:18           |
| 2コア | **7:23**        | **4:14**           |
| 4コア | 7:37        | 4:40           |
| 8コア | 8:06        | 5:11


うーんなにかUbuntu側の設定の問題なのか、Tensorflow(or keras)の仕様なのか、、謎
