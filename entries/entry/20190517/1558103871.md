---
Title: Jetson Nanoを使ってYOLOでリアルタイム物体認識する
Category:
- jetson
Date: 2019-05-17T23:37:51+09:00
URL: https://blog.turai.work/entry/20190517/1558103871
EditURL: https://blog.hatena.ne.jp/thr3a/thr3a.hatenablog.com/atom/entry/17680117127139251103
---

Jetson Nanoにカメラを接続して、YOLOでリアルタイム物体認識を行う

# 用意するもの

- Jetson Nano （当然）

- Raspberry Pi Camera **V2**でないと動かないので注意

[asin:B07B8R2W93:detail]

あと認証があるらしくパチもんも動かないらしい

カメラ＆GPU使うと結構電気消費するらしいので、できればMicroUSB経由ではなくちゃんとした電源経由のほうが安定する。（たまにハングアップする


# インストール

YOLOは所詮物体検出アルゴリズムの一種にすぎないので、インターフェイスが必要。が、コードは書きたくないのでYOLO対応のニューラルネットワークフレームワークであるdarknetを使う

[pjreddie/darknet: Convolutional Neural Networks](https://github.com/pjreddie/darknet)

darknetを使うにあたって.bashrcに以下を追記

```sh
export PATH=/usr/local/cuda/bin:${PATH}
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:${LD_LIBRARY_PATH}
```

git cloneでdarknetを落とす

```
git clone https://github.com/pjreddie/darknet.git
```

YOLOのデータファイルをダウンロード　デフォルトではyolov3を使うが、Jetson Nanoでは残念ながら力不足なのでTINYバージョンを使う

```
cd darknet
# wget https://pjreddie.com/media/files/yolov3.weights
wget https://pjreddie.com/media/files/yolov3-tiny.weights
```

ビルド、の前にMakefileの先頭を修正してGPUを使うようにする。以下のように合わせる

```
GPU=1
CUDNN=1
CUDNN_HALF=1
OPENCV=1
AVX=0
OPENMP=1
LIBSO=1
ZED_CAMERA=0
```

でビルド

```
make -j4
```

darknet自体のビルドは軽いが、Jetson Nanoだとやはり時間はかかる。

# いざ画像判定

プロジェクトの中にサンプル画像が入っているのでそれを使って判定してみる。

```
./darknet detect cfg/yolov3-tiny.cfg yolov3-tiny.weights data/dog.jpg
```

# カメラ経由で物体認識

当然だが、予めカメラが接続できていることが前提

```
./darknet detector demo cfg/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights "'nvarguscamerasrc ! video/x-raw(memory:NVMM), width=1280, height=720, format=(string)NV12, framerate=(fraction)30/1 ! nvtee ! nvvidconv flip-method=2 ! video/x-raw, width=(int)1280, height=(int)720, format=(string)BGRx ! videoconvert ! appsink'"
```

デフォルトのnvarguscamerasrcから得られるカメラ画像は上下逆なので補正する必要がある。（それに合わせてOpenCVを自前ビルドすればいいのかもしれないが未確認

試しにペットボトルかざしたら「bottle」と出た。おおよそ１５FPSなので若干モッサリ感は否めない。
